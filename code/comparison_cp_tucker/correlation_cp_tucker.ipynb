{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0275b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust the path as needed to reach your project root from the notebook's location\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed342b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b9f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_utrecht_weekday = {\n",
    "    \"C3\": (4, 4, 3)\n",
    "}\n",
    "\n",
    "mapping_utrecht_weekend = {\n",
    "    \"C3\": (4, 4, 3)\n",
    "}\n",
    "mapping_rotterdam_weekday = {\n",
    "    \"C1\": (1, 3, 2),\n",
    "    \"C4\": (3, 2, 1),\n",
    "    \"C3\": (4, 4, 3)\n",
    "}\n",
    "mapping_rotterdam_weekend = {\n",
    "    \"C1\": (1, 2, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1128bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the decomposition file path of the final CP and Tucker decompositions\n",
    "decomposition_path_weekday_utrecht_cp = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/CP/final/peak hours normalized/utrecht/odt_no_same_od_no_rare_od_fixed_thresh_normalizedPeaks/odt_utrecht_hourly_weekday/run_20250610_001409/rank_5/odt_processed_utrecht_hourly_weekday_factors.npz\"\n",
    "decomposition_path_weekday_utrecht_tucker = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/tucker/hourly_analysis/odt_utrecht_hourly_weekday/MU/run_20250610_123349/rank_5_5_4/odt_utrecht_hourly_weekday_factors.npz\"\n",
    "\n",
    "decomposition_path_weekend_utrecht_cp = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/CP/final/peak hours normalized/utrecht/odt_no_same_od_no_rare_od_fixed_thresh_normalizedPeaks/odt_utrecht_hourly_weekend/run_20250610_001322/rank_4/odt_processed_utrecht_hourly_weekend_factors.npz\"\n",
    "decomposition_path_weekend_utrecht_tucker = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/tucker/hourly_analysis/odt_utrecht_hourly_weekend/MU/run_20250610_123349/rank_4_4_5/odt_utrecht_hourly_weekend_factors.npz\"\n",
    "\n",
    "decomposition_path_weekday_rotterdam_cp = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/CP/final/peak hours normalized/rotterdam/odt_no_same_od_no_rare_od_fixed_thresh_normalizedPeaks/odt_rotterdam_hourly_weekday/run_20250610_001727/rank_6/odt_processed_rotterdam_hourly_weekday_factors.npz\"\n",
    "decomposition_path_weekday_rotterdam_tucker = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/tucker/hourly_analysis/odt_rotterdam_hourly_weekday/MU/run_20250610_123349/rank_4_4_3/odt_rotterdam_hourly_weekday_factors.npz\"\n",
    "\n",
    "decomposition_path_weekend_rotterdam_cp = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/CP/final/peak hours normalized/rotterdam/odt_no_same_od_no_rare_od_fixed_thresh_normalizedPeaks/odt_rotterdam_hourly_weekend/run_20250610_001652/rank_6/odt_processed_rotterdam_hourly_weekend_factors.npz\"\n",
    "decomposition_path_weekend_rotterdam_tucker = str(\n",
    "    PROJECT_ROOT) + \"/data/results/decompositions/tucker/hourly_analysis/odt_rotterdam_hourly_weekend/MU/run_20250610_123349/rank_4_4_3/odt_rotterdam_hourly_weekend_factors.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61bdbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peterfalterbaum/Documents/Nova/thesis local/implementation/public_implementation/data/results/decompositions/tucker/hourly_analysis/odt_rotterdam_hourly_weekend/MU/run_20250610_123349/rank_4_4_3/odt_rotterdam_hourly_weekend_factors.npz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposition_path_weekend_rotterdam_tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36cce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decomposition_data(decomposition_path, granularity, return_core=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    decomposition_path : str or Path\n",
    "        Path to the .npz file containing factor matrices (and possibly 'core').\n",
    "    granularity : str\n",
    "        'Weekday' or 'Weekend' (used to pick the correct index mapping file).\n",
    "    return_core : bool, optional\n",
    "        If True, also return the Tucker core tensor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    origin_factor : np.ndarray\n",
    "    destination_factor : np.ndarray\n",
    "    time_factor : np.ndarray\n",
    "    core : np.ndarray (only if return_core=True)\n",
    "    idx_to_origins : dict\n",
    "    idx_to_destinations : dict\n",
    "    \"\"\"\n",
    "    # 1. Determine run directory and read summary\n",
    "    decomposition_path = Path(decomposition_path)\n",
    "    run_dir = decomposition_path.parent.parent\n",
    "    run_summary_path = run_dir / \"run_summary.json\"\n",
    "    if not run_summary_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing run_summary.json at {run_summary_path}\")\n",
    "    with open(run_summary_path, \"r\") as f:\n",
    "        run_summary = json.load(f)\n",
    "\n",
    "    # 2. Load the decomposition .npz\n",
    "    data = np.load(decomposition_path, allow_pickle=True)\n",
    "    origin_factor = data[\"factors\"][0]\n",
    "    destination_factor = data[\"factors\"][1]\n",
    "    time_factor = data[\"factors\"][2]\n",
    "\n",
    "    # 3. Optionally extract the Tucker core\n",
    "    core = None\n",
    "    if return_core:\n",
    "        if \"core\" not in data:\n",
    "            raise KeyError(\n",
    "                \"No 'core' array found in decomposition file for Tucker.\")\n",
    "        core = data[\"core\"]\n",
    "\n",
    "    # 4. Load index mappings\n",
    "    tensor_file = Path(run_summary[\"tensor_info\"][\"file\"])\n",
    "    tensor_dir = tensor_file.parent\n",
    "    city = \"utrecht\" if \"utrecht\" in tensor_file.name.lower() else \"rotterdam\"\n",
    "    idx_map_file = tensor_dir / \\\n",
    "        f\"index_mappings_{city}_{granularity.lower()}_hourly.json\"\n",
    "    if not idx_map_file.exists():\n",
    "        raise FileNotFoundError(f\"Index mapping not found: {idx_map_file}\")\n",
    "    with open(idx_map_file, \"r\") as f:\n",
    "        idx_maps = json.load(f)\n",
    "\n",
    "    idx_to_origins = idx_maps[\"idx_to_origins\"]\n",
    "    idx_to_destinations = idx_maps[\"idx_to_destinations\"]\n",
    "\n",
    "    # 5. Return\n",
    "    if return_core:\n",
    "        return origin_factor, destination_factor, time_factor, core, idx_to_origins, idx_to_destinations\n",
    "    else:\n",
    "        return origin_factor, destination_factor, time_factor, idx_to_origins, idx_to_destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8e9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def compare_cp_vs_tucker(\n",
    "    cp_path: str,\n",
    "    tk_path: str,\n",
    "    mapping: dict[str, tuple[int, int, int]],\n",
    "    granularity: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each CP‐component label (e.g. \"C3\") in `mapping`, compute\n",
    "    Pearson‐r between:\n",
    "      - CP origin[:,k] vs Tucker origin[:,r_o-1],\n",
    "      - CP dest   [:,k] vs Tucker dest   [:,r_d-1],\n",
    "      - CP time   [:,k] vs Tucker time   [:,r_t-1].\n",
    "\n",
    "    Returns a DataFrame indexed by CP‐label with columns\n",
    "    ['origin_r','destination_r','time_r'].\n",
    "    \"\"\"\n",
    "    # load CP factors (ignore core)\n",
    "    A_cp, B_cp, C_cp, _, _ = get_decomposition_data(\n",
    "        cp_path, granularity, return_core=False)\n",
    "    # load Tucker factors + core (we’ll just ignore G)\n",
    "    A_tk, B_tk, C_tk, _, _ = get_decomposition_data(\n",
    "        tk_path, granularity, return_core=False)\n",
    "\n",
    "    rows = []\n",
    "    for cp_label, (ro, rd, rt) in mapping.items():\n",
    "        k = int(cp_label[1:]) - 1       # zero-based CP component idx\n",
    "        i_ro, i_rd, i_rt = ro-1, rd-1, rt-1  # zero-based Tucker indices\n",
    "\n",
    "        # compute Pearson r\n",
    "        or_r = pearsonr(A_cp[:, k], A_tk[:, i_ro])[0]\n",
    "        dr_r = pearsonr(B_cp[:, k], B_tk[:, i_rd])[0]\n",
    "        tr_r = pearsonr(C_cp[:, k], C_tk[:, i_rt])[0]\n",
    "\n",
    "        rows.append({\n",
    "            'cp_label':      cp_label,\n",
    "            'origin_r':      or_r,\n",
    "            'destination_r': dr_r,\n",
    "            'time_r':        tr_r\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows).set_index('cp_label')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6233f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def best_cp_tk_matches(cp_path, tk_path, granularity):\n",
    "    # load factors only (ignore core and mappings)\n",
    "    A_cp, B_cp, C_cp, * \\\n",
    "        _ = get_decomposition_data(cp_path, granularity, return_core=False)\n",
    "    A_tk, B_tk, C_tk, G, * \\\n",
    "        _ = get_decomposition_data(tk_path, granularity, return_core=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f38988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def best_cp_tk_matches(cp_path: str,\n",
    "                       tk_path: str,\n",
    "                       granularity: str,\n",
    "                       tcore: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each CP component k, finds the Tucker triplet (r_o,r_d,r_t)\n",
    "    that maximizes the average Pearson-r across origin/destination/time,\n",
    "    and returns a DataFrame with:\n",
    "      - r_origin, r_destination, r_time, r_mean\n",
    "      - whether that triplet is among the top‐energy triplets covering tcore% of G’s energy\n",
    "      - the rank position of that triplet in G when sorted by squared‐core energy\n",
    "    \"\"\"\n",
    "    # load factors and core\n",
    "    A_cp, B_cp, C_cp, * \\\n",
    "        _ = get_decomposition_data(cp_path, granularity, return_core=False)\n",
    "    A_tk, B_tk, C_tk, G_tk, * \\\n",
    "        _ = get_decomposition_data(tk_path, granularity, return_core=True)\n",
    "\n",
    "    K = A_cp.shape[1]\n",
    "    R1, R2, R3 = G_tk.shape\n",
    "\n",
    "    # precompute Tucker‐core energy ranking\n",
    "    E = G_tk**2\n",
    "    flat = E.ravel()\n",
    "    flat_idx = np.argsort(flat)[::-1]\n",
    "    cum_energy = np.cumsum(flat[flat_idx])\n",
    "    total_energy = cum_energy[-1]\n",
    "    M = np.searchsorted(cum_energy, tcore * total_energy) + 1\n",
    "    sel = flat_idx[:M]\n",
    "    sel_set = set(sel)\n",
    "    # map each flat‐index to its 1-based rank in the sorted list\n",
    "    rank_map = {fi: rank+1 for rank, fi in enumerate(flat_idx)}\n",
    "\n",
    "    # list all zero‐based triplets\n",
    "    triplets = [(i, j, k)\n",
    "                for i in range(R1)\n",
    "                for j in range(R2)\n",
    "                for k in range(R3)]\n",
    "    # similarity matrix\n",
    "    S = np.zeros((K, len(triplets)))\n",
    "    for k_cp in range(K):\n",
    "        for m, (i_ro, i_rd, i_rt) in enumerate(triplets):\n",
    "            or_r = pearsonr(A_cp[:, k_cp], A_tk[:, i_ro])[0]\n",
    "            dr_r = pearsonr(B_cp[:, k_cp], B_tk[:, i_rd])[0]\n",
    "            tr_r = pearsonr(C_cp[:, k_cp], C_tk[:, i_rt])[0]\n",
    "            S[k_cp, m] = (or_r + dr_r + tr_r) / 3.0\n",
    "\n",
    "    # build output\n",
    "    rows = []\n",
    "    for k_cp in range(K):\n",
    "        best_m = S[k_cp].argmax()\n",
    "        i_ro, i_rd, i_rt = triplets[best_m]\n",
    "\n",
    "        or_r = pearsonr(A_cp[:, k_cp], A_tk[:, i_ro])[0]\n",
    "        dr_r = pearsonr(B_cp[:, k_cp], B_tk[:, i_rd])[0]\n",
    "        tr_r = pearsonr(C_cp[:, k_cp], C_tk[:, i_rt])[0]\n",
    "        mean_r = S[k_cp, best_m]\n",
    "\n",
    "        # compute the flat‐index and its energy‐rank and top80‐flag\n",
    "        flat_index = np.ravel_multi_index((i_ro, i_rd, i_rt), G_tk.shape)\n",
    "        in_top80 = flat_index in sel_set\n",
    "        energy_rank = rank_map[flat_index]\n",
    "\n",
    "        rows.append({\n",
    "            'cp_component':    f\"C{k_cp+1}\",\n",
    "            'tucker_triplet':  (i_ro+1, i_rd+1, i_rt+1),\n",
    "            'r_origin':        or_r,\n",
    "            'r_destination':   dr_r,\n",
    "            'r_time':          tr_r,\n",
    "            'r_mean':          mean_r,\n",
    "            'in_top80':        in_top80,\n",
    "            'energy_rank':     energy_rank\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).set_index('cp_component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5e446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def best_cp_tk_matches(cp_path: str,\n",
    "                       tk_path: str,\n",
    "                       granularity: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each CP component k, finds the Tucker triplet (r_o,r_d,r_t)\n",
    "    that maximizes the average Pearson-r across origin/destination/time,\n",
    "    and returns a DataFrame with all four correlation scores.\n",
    "    \"\"\"\n",
    "    # load factors (and core, mappings—we ignore core here)\n",
    "    A_cp, B_cp, C_cp, * \\\n",
    "        _ = get_decomposition_data(cp_path, granularity, return_core=False)\n",
    "    A_tk, B_tk, C_tk, G_tk, * \\\n",
    "        _ = get_decomposition_data(tk_path, granularity, return_core=True)\n",
    "\n",
    "    K = A_cp.shape[1]\n",
    "    R1, R2, R3 = G_tk.shape\n",
    "\n",
    "    # build list of all zero-based triplets\n",
    "    triplets = [(i, j, k)\n",
    "                for i in range(R1)\n",
    "                for j in range(R2)\n",
    "                for k in range(R3)]\n",
    "    M = len(triplets)\n",
    "\n",
    "    # prepare similarity storage\n",
    "    S = np.zeros((K, M))\n",
    "    # precompute all correlations\n",
    "    for k_cp in range(K):\n",
    "        for m, (i_ro, i_rd, i_rt) in enumerate(triplets):\n",
    "            or_r = pearsonr(A_cp[:, k_cp], A_tk[:, i_ro])[0]\n",
    "            dr_r = pearsonr(B_cp[:, k_cp], B_tk[:, i_rd])[0]\n",
    "            tr_r = pearsonr(C_cp[:, k_cp], C_tk[:, i_rt])[0]\n",
    "            S[k_cp, m] = (or_r + dr_r + tr_r) / 3.0\n",
    "\n",
    "    # build output rows\n",
    "    rows = []\n",
    "    for k_cp in range(K):\n",
    "        best_m = S[k_cp].argmax()\n",
    "        i_ro, i_rd, i_rt = triplets[best_m]\n",
    "\n",
    "        or_r = pearsonr(A_cp[:, k_cp], A_tk[:, i_ro])[0]\n",
    "        dr_r = pearsonr(B_cp[:, k_cp], B_tk[:, i_rd])[0]\n",
    "        tr_r = pearsonr(C_cp[:, k_cp], C_tk[:, i_rt])[0]\n",
    "        mean_r = S[k_cp, best_m]\n",
    "\n",
    "        rows.append({\n",
    "            'cp_component':   f\"C{k_cp+1}\",\n",
    "            'tucker_triplet': (i_ro+1, i_rd+1, i_rt+1),\n",
    "            'r_origin':       or_r,\n",
    "            'r_destination':  dr_r,\n",
    "            'r_time':         tr_r,\n",
    "            'r_mean':         mean_r\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).set_index('cp_component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707be315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          origin_r  destination_r    time_r\n",
      "cp_label                                   \n",
      "C1        0.999627       0.999494  0.993979\n",
      "C4        0.994307       0.987728  0.969292\n",
      "C3        0.924466       0.921360  0.646027\n"
     ]
    }
   ],
   "source": [
    "# Set city and time scope, select variables automatically\n",
    "city: str = \"rotterdam\"\n",
    "time_scope: str = \"weekday\"\n",
    "\n",
    "cp_path: str = globals()[f\"decomposition_path_{time_scope}_{city}_cp\"]\n",
    "tk_path: str = globals()[f\"decomposition_path_{time_scope}_{city}_tucker\"]\n",
    "mapping: dict[str, tuple[int, int, int]] = globals()[\n",
    "    f\"mapping_{city}_{time_scope}\"]\n",
    "\n",
    "df = compare_cp_vs_tucker(\n",
    "    cp_path,\n",
    "    tk_path,\n",
    "    mapping,\n",
    "    granularity=time_scope\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186c33e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: utrecht, Time scope: weekday\n",
      "             tucker_triplet  r_origin  r_destination    r_time    r_mean\n",
      "cp_component                                                            \n",
      "C1                (1, 3, 3)  0.994522       0.990345  0.886916  0.957261\n",
      "C2                (2, 5, 1)  0.770017       0.806487  0.871061  0.815855\n",
      "C3                (4, 1, 4)  0.972348       0.967990  0.957775  0.966038\n",
      "C4                (3, 1, 3)  0.862260       0.924068  0.756835  0.847721\n",
      "C5                (3, 4, 2)  0.572917       0.898973  0.901884  0.791258\n",
      "\n",
      "\n",
      "\n",
      "City: utrecht, Time scope: weekend\n",
      "             tucker_triplet  r_origin  r_destination    r_time    r_mean\n",
      "cp_component                                                            \n",
      "C1                (3, 1, 4)  0.849633       0.991449  0.644595  0.828559\n",
      "C2                (4, 3, 5)  0.993408       0.975974  0.970928  0.980104\n",
      "C3                (2, 2, 2)  0.944764       0.957638  0.896753  0.933052\n",
      "C4                (2, 2, 1)  0.332182       0.404953  0.822828  0.519987\n",
      "\n",
      "\n",
      "\n",
      "City: rotterdam, Time scope: weekday\n",
      "             tucker_triplet  r_origin  r_destination    r_time    r_mean\n",
      "cp_component                                                            \n",
      "C1                (1, 3, 2)  0.999627       0.999494  0.993979  0.997700\n",
      "C2                (2, 1, 1)  0.897241       0.979660  0.782149  0.886350\n",
      "C3                (4, 4, 3)  0.924466       0.921360  0.646027  0.830618\n",
      "C4                (3, 2, 1)  0.994307       0.987728  0.969292  0.983776\n",
      "C5                (2, 1, 3)  0.438954       0.914032  0.603234  0.652073\n",
      "C6                (4, 4, 1)  0.453199       0.460813  0.608561  0.507524\n",
      "\n",
      "\n",
      "\n",
      "City: rotterdam, Time scope: weekend\n",
      "             tucker_triplet  r_origin  r_destination    r_time    r_mean\n",
      "cp_component                                                            \n",
      "C1                (3, 2, 3)  0.179837       0.321003  0.270425  0.257088\n",
      "C2                (4, 1, 2)  0.983895       0.976108  0.977573  0.979192\n",
      "C3                (4, 2, 3)  0.985444       0.422352  0.406832  0.604876\n",
      "C4                (1, 4, 3)  0.735586       0.824727  0.627222  0.729178\n",
      "C5                (3, 1, 3)  0.365772       0.282652  0.318843  0.322423\n",
      "C6                (4, 2, 1)  0.987112       0.946220  0.968421  0.967251\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for city in [\"utrecht\", \"rotterdam\"]:\n",
    "    for time_scope in [\"weekday\", \"weekend\"]:\n",
    "        cp_path: str = globals()[f\"decomposition_path_{time_scope}_{city}_cp\"]\n",
    "        tk_path: str = globals()[\n",
    "            f\"decomposition_path_{time_scope}_{city}_tucker\"]\n",
    "        mapping: dict[str, tuple[int, int, int]] = globals()[\n",
    "            f\"mapping_{city}_{time_scope}\"]\n",
    "\n",
    "        df = best_cp_tk_matches(\n",
    "            cp_path,\n",
    "            tk_path,\n",
    "            granularity=time_scope\n",
    "        )\n",
    "        print(f\"City: {city}, Time scope: {time_scope}\")\n",
    "        print(df)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4646269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocketRiding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
